# LLM Configuration
LLM_PROVIDER=openai
LLM_MODEL=gpt-4o-mini
OPENAI_API_KEY=your_openai_api_key_here
OLLAMA_BASE_URL=http://localhost:11434

# Ingestion
ARXIV_MAX_RESULTS=50
GITHUB_TRENDING_TOPICS=ai-safety,security

# Data Storage
HF_DATASET_NAME=your-username/ai-safety-radar
HF_TOKEN=your_hf_token_here

# Processing
MAX_CONCURRENT_REQUESTS=10
REQUEST_TIMEOUT=30
